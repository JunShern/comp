{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GPU verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanjunshern/tensorflow/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# Test GPU on machine\n",
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Investigating recorded input/output from live demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pianoroll_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import pypianoroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_pianoroll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-8a5af829a380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_pianoroll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recorded_pianoroll.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcomp_pianoroll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generated_pianoroll.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_pianoroll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Plot comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generated_pianoroll' is not defined"
     ]
    }
   ],
   "source": [
    "input_pianoroll = np.load('recorded_pianoroll.npy').swapaxes(0,1).reshape(96, 128)\n",
    "comp_pianoroll = np.load('generated_pianoroll.npy').swapaxes(0,1).reshape(96, 128)\n",
    "test = generated_pianoroll\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 6, forward=True)\n",
    "ax.set_title('Input')\n",
    "pypianoroll.plot_pianoroll(ax, test, beat_resolution=24)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Play comparison\n",
    "# pianoroll_utils.playPianoroll(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Investigating playpianoroll_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "MODEL_AUTOENCODER_FILE = './models/autoencoder_v4.h5'\n",
    "autoencoder = load_model(MODEL_AUTOENCODER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting autoencoder stuff (1, 128, 96, 1)\n",
      "55.90551181102363\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "# Normalize input_pianoroll\n",
    "input_pianoroll = np.load('recorded_pianoroll.npy')\n",
    "input_pianoroll = input_pianoroll / 127.\n",
    "# Get encoding of the input\n",
    "input_pianoroll = input_pianoroll.reshape(1, 128, 96, 1)\n",
    "autoencoder_output = autoencoder.predict(input_pianoroll) # (1, 128, 96, 1)\n",
    "assert autoencoder_output.shape == (1, 128, 96, 1)\n",
    "print \"Getting autoencoder stuff\", autoencoder_output.shape\n",
    "# print np.sum(input_pianoroll - autoencoder_output)\n",
    "print np.sum(input_pianoroll)\n",
    "print np.amin(autoencoder_output)\n",
    "# output_pianoroll = autoencoder_output[0].reshape(128, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  3.4705973  20.77994    24.45203     0.877367    0.          3.9844081\n",
      "  6.5914383   5.171249    1.4545087   2.5562441   3.8582234   0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.03607762  9.261589   13.108125   16.930813   20.213509   17.428322\n",
      " 17.123474    3.6582694   3.8401468   0.          0.          0.90885544\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pianoroll_utils\n",
    "\n",
    "sample_input = input_pianoroll.reshape(128,96).swapaxes(0,1).reshape(96, 128) * 127\n",
    "sample_output = autoencoder_output[0].swapaxes(0,1).reshape(96, 128) * 127\n",
    "print sample_output[:,48]\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(10, 6, forward=True)\n",
    "ax[0].set_title('Input')\n",
    "ax[1].set_title('Output')\n",
    "pypianoroll.plot_pianoroll(ax[0], sample_input, beat_resolution=24, cmap='inferno')\n",
    "pypianoroll.plot_pianoroll(ax[1], sample_output, beat_resolution=24, cmap='inferno')\n",
    "fig.tight_layout()\n",
    "\n",
    "pianoroll_utils.playPianoroll(sample_input)\n",
    "pianoroll_utils.playPianoroll(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 96)\n",
      "\n",
      "Input\n",
      "\n",
      "Output\n"
     ]
    }
   ],
   "source": [
    "input_pianoroll = np.load('recorded_pianoroll.npy')\n",
    "print input_pianoroll.shape\n",
    "\n",
    "print(\"\")\n",
    "print(\"Input\")\n",
    "play_midi_events(pianoroll_2_events(input_pianoroll))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Output\")\n",
    "play_midi_events(pianoroll_2_events(autoencoder_output.reshape(128,96) * 127))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76522815\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  4.5353756  27.15522    31.953907    1.146543    0.          5.206824\n",
      "  8.61369     6.757787    1.9007516   3.3404996   5.041926    0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.04714623 12.103043   17.129694   22.125185   26.415009   22.775328\n",
      " 22.376951    4.7806253   5.0183034   0.          0.          1.1876922\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# print np.amax(autoencoder_output)\n",
    "output = autoencoder_output.reshape(128,96) / np.amax(autoencoder_output) * 127\n",
    "print output[48,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "note_on channel=0 note=48 velocity=117 time=0.25\n",
    "note_on channel=0 note=48 velocity=0 time=0.0840909090909\n",
    "note_on channel=0 note=48 velocity=127 time=0.0204545454545\n",
    "note_on channel=0 note=48 velocity=0 time=0.125\n",
    "note_on channel=0 note=41 velocity=126 time=0.0613636363636\n",
    "note_on channel=0 note=40 velocity=127 time=0.188636363636\n",
    "note_on channel=0 note=40 velocity=0 time=0.0409090909091\n",
    "note_on channel=0 note=53 velocity=127 time=0.188636363636\n",
    "note_on channel=0 note=45 velocity=127 time=0.0204545454545\n",
    "note_on channel=0 note=45 velocity=0 time=0.104545454545\n",
    "note_on channel=0 note=45 velocity=127 time=0.0204545454545\n",
    "note_on channel=0 note=45 velocity=0 time=0.0613636363636\n",
    "note_on channel=0 note=45 velocity=80 time=0.0431818181818\n",
    "note_on channel=0 note=45 velocity=0 time=0.0409090909091\n",
    "note_on channel=0 note=48 velocity=113 time=0\n",
    "note_on channel=0 note=48 velocity=0 time=0.188636363636\n",
    "note_on channel=0 note=48 velocity=90 time=0.0409090909091\n",
    "note_on channel=0 note=48 velocity=0 time=0.0204545454545\n",
    "note_on channel=0 note=53 velocity=0 time=0.188636363636\n",
    "note_on channel=0 note=53 velocity=127 time=0.0409090909091\n",
    "note_on channel=0 note=41 velocity=0 time=0.145454545455\n",
    "note_on channel=0 note=55 velocity=127 time=0.104545454545\n",
    "note_on channel=0 note=53 velocity=0 time=0.0204545454545\n",
    "note_on channel=0 note=55 velocity=0 time=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "note_on channel=5 note=48 velocity=15 time=0\n",
    "note_on channel=5 note=48 velocity=0 time=0\n",
    "note_on channel=5 note=48 velocity=3 time=0\n",
    "note_on channel=5 note=48 velocity=0 time=0\n",
    "note_on channel=5 note=41 velocity=8 time=0\n",
    "note_on channel=5 note=41 velocity=0 time=0\n",
    "note_on channel=5 note=41 velocity=50 time=0\n",
    "note_on channel=5 note=40 velocity=3 time=0\n",
    "note_on channel=5 note=40 velocity=0 time=0\n",
    "note_on channel=5 note=53 velocity=66 time=0\n",
    "note_on channel=5 note=45 velocity=14 time=0\n",
    "note_on channel=5 note=45 velocity=0 time=0\n",
    "note_on channel=5 note=45 velocity=4 time=0\n",
    "note_on channel=5 note=45 velocity=0 time=0\n",
    "note_on channel=5 note=45 velocity=2 time=0\n",
    "note_on channel=5 note=45 velocity=0 time=0\n",
    "note_on channel=5 note=48 velocity=12 time=0\n",
    "note_on channel=5 note=48 velocity=0 time=0\n",
    "note_on channel=5 note=53 velocity=0 time=0\n",
    "note_on channel=5 note=53 velocity=32 time=0\n",
    "note_on channel=5 note=41 velocity=0 time=0\n",
    "note_on channel=5 note=55 velocity=29 time=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM sequence learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- Keras [docs](https://keras.io/preprocessing/sequence/#timeseriesgenerator) for TimeSeriesGenerator\n",
    "- [StackOverflow](https://stackoverflow.com/questions/49555701/timeseriesgenerator-for-two-or-more-inputs) question on multiple input timeseriesgenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/human/tensorflow/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "from keras.models import Model, Sequential  \n",
    "from keras.layers import Input, Activation, Dense, LSTM, Concatenate\n",
    "# from keras.layers.core import Dense, Activation\n",
    "# from keras.layers.recurrent import LSTM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Sequence predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class TimeseriesGeneratorCustom(Sequence):\n",
    "    \"\"\"Utility class for generating batches of temporal data.\n",
    "    This class takes in a sequence of data-points gathered at\n",
    "    equal intervals, along with time series parameters such as\n",
    "    stride, length of history, etc., to produce batches for\n",
    "    training/validation.\n",
    "    # Arguments\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, targets, length,\n",
    "                 sampling_rate=1,\n",
    "                 stride=1,\n",
    "                 start_index=0,\n",
    "                 end_index=None,\n",
    "                 shuffle=False,\n",
    "                 reverse=False,\n",
    "                 batch_size=128):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.length = length\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.stride = stride\n",
    "        self.start_index = start_index + length\n",
    "        if end_index is None:\n",
    "            end_index = len(data) - 1\n",
    "        self.end_index = end_index\n",
    "        self.shuffle = shuffle\n",
    "        self.reverse = reverse\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if self.start_index > self.end_index:\n",
    "            raise ValueError('`start_index+length=%i > end_index=%i` '\n",
    "                             'is disallowed, as no part of the sequence '\n",
    "                             'would be left to be used as current step.'\n",
    "                             % (self.start_index, self.end_index))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(\n",
    "            (self.end_index - self.start_index + 1) /\n",
    "            (self.batch_size * self.stride)))\n",
    "\n",
    "    def _empty_batch(self, num_rows):\n",
    "        samples_shape = [num_rows, self.length // self.sampling_rate]\n",
    "        samples_shape.extend(self.data.shape[1:])\n",
    "        targets_shape = [num_rows]\n",
    "        targets_shape.extend(self.targets.shape[1:])\n",
    "        return np.empty(samples_shape), np.empty(targets_shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.shuffle:\n",
    "            rows = np.random.randint(\n",
    "                self.start_index, self.end_index + 1, size=self.batch_size)\n",
    "        else:\n",
    "            i = self.start_index + self.batch_size * self.stride * index\n",
    "            rows = np.arange(i, min(i + self.batch_size *\n",
    "                                    self.stride, self.end_index + 1), self.stride)\n",
    "\n",
    "        samples, targets = self._empty_batch(len(rows))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - self.length, rows[j], self.sampling_rate)\n",
    "            samples[j] = self.data[indices]\n",
    "            targets[j] = self.targets[rows[j]]\n",
    "        if self.reverse:\n",
    "            return samples[:, ::-1, ...], targets\n",
    "        return samples, targets\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Method called at the end of every epoch.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create an infinite generator that iterate over the Sequence.\"\"\"\n",
    "        while True:\n",
    "            for item in (self[i] for i in range(len(self))):\n",
    "                yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use keras TimeseriesGenerator to turn a sequence\n",
    "# into multiple windows of sequences\n",
    "WINDOW_LENGTH = 4\n",
    "\n",
    "# def get_generator(data, targets, window_length = 5, batch_size = 32):\n",
    "#     while True:\n",
    "#         data_gen = TimeseriesGenerator(data, targets, length=window_length, \n",
    "#                                        sampling_rate=1, batch_size=batch_size)\n",
    "#         for i in range(len(data_gen)):\n",
    "#             x, y = data_gen[i]\n",
    "#             yield x, y\n",
    "\n",
    "class CustomGen(TimeseriesGenerator):\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = TimeseriesGenerator.__getitem__(self, idx)\n",
    "        # do processing here\n",
    "        return x, y\n",
    "\n",
    "data = np.arange(0,100).reshape(-1,1)\n",
    "data_gen_custom = TimeseriesGeneratorCustom(data, data, length=WINDOW_LENGTH, sampling_rate=1, batch_size=1)\n",
    "data_gen = TimeseriesGenerator(data, data, length=WINDOW_LENGTH, sampling_rate=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4, 1)              0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 42,841\n",
      "Trainable params: 42,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_dim = 1\n",
    "input1 = Input(shape=(WINDOW_LENGTH, data_dim))\n",
    "lstm1 = LSTM(100)(input1)\n",
    "\n",
    "hidden = Dense(20, activation='relu')(lstm1)\n",
    "output = Dense(data_dim, activation='linear')(hidden)\n",
    "\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 2470.8388 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2437.9167 - acc: 0.0312\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1884.0048 - acc: 0.0625\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 861.9349 - acc: 0.0312\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 885.3431 - acc: 0.0312\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 548.7989 - acc: 0.0625\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 324.5852 - acc: 0.0938\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 129.7269 - acc: 0.1250\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 88.3675 - acc: 0.1250\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 38.0719 - acc: 0.2188\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 20.5961 - acc: 0.2500\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 19.4715 - acc: 0.1875\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 10.4649 - acc: 0.2188\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3105 - acc: 0.2188\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.0287 - acc: 0.0938\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.6308 - acc: 0.3438\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4228 - acc: 0.1562\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.4034 - acc: 0.1875\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.6298 - acc: 0.2500\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1945 - acc: 0.2188\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7849 - acc: 0.2812\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.7766 - acc: 0.1875\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.2491 - acc: 0.1875\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.8280 - acc: 0.1562\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.5370 - acc: 0.3125\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.5868 - acc: 0.1875\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.7718 - acc: 0.2500\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.4506 - acc: 0.3750\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.2004 - acc: 0.4062\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.8445 - acc: 0.2812\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.6484 - acc: 0.3438\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.9718 - acc: 0.4375\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.2157 - acc: 0.2188\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.0758 - acc: 0.4062\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.2353 - acc: 0.3438\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.4091 - acc: 0.2812\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.9916 - acc: 0.3438\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.2842 - acc: 0.1875\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9059 - acc: 0.3438\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.7559 - acc: 0.3125\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.0484 - acc: 0.2500\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.5914 - acc: 0.4062\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1536 - acc: 0.3438\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.3359 - acc: 0.4375\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6905 - acc: 0.4375\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.1603 - acc: 0.3750\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6341 - acc: 0.4062\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.9574 - acc: 0.2812\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.5818 - acc: 0.3438\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.6340 - acc: 0.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f776eb97d10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now train the model\n",
    "# batch_size should be appropriate to your memory size\n",
    "model.fit_generator(generator=data_gen_custom,\n",
    "                    steps_per_epoch=32,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88.76638]]\n"
     ]
    }
   ],
   "source": [
    "input1 = np.arange(80,84).reshape(1,WINDOW_LENGTH,1)\n",
    "\n",
    "predicted = model.predict(input1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-sequence predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class TimeseriesGeneratorTwoInputs(Sequence):\n",
    "    \"\"\"Utility class for generating batches of temporal data.\n",
    "    This class takes in a sequence of data-points gathered at\n",
    "    equal intervals, along with time series parameters such as\n",
    "    stride, length of history, etc., to produce batches for\n",
    "    training/validation.\n",
    "    \n",
    "    Adapted from the TimeseriesGenerator class:\n",
    "    https://github.com/keras-team/keras/blob/master/keras/utils/data_utils.py#L302\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data1, data2, targets, length,\n",
    "                 sampling_rate=1,\n",
    "                 stride=1,\n",
    "                 start_index=0,\n",
    "                 end_index=None,\n",
    "                 shuffle=False,\n",
    "                 reverse=False,\n",
    "                 batch_size=128):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        assert len(data1) == len(data2)\n",
    "        self.targets = targets\n",
    "        self.length = length\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.stride = stride\n",
    "        self.start_index = start_index + length\n",
    "        if end_index is None:\n",
    "            end_index = len(data1) - 1\n",
    "        self.end_index = end_index\n",
    "        self.shuffle = shuffle\n",
    "        self.reverse = reverse\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if self.start_index > self.end_index:\n",
    "            raise ValueError('`start_index+length=%i > end_index=%i` '\n",
    "                             'is disallowed, as no part of the sequence '\n",
    "                             'would be left to be used as current step.'\n",
    "                             % (self.start_index, self.end_index))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(\n",
    "            (self.end_index - self.start_index + 1) /\n",
    "            (self.batch_size * self.stride)))\n",
    "\n",
    "    def _empty_batch(self, num_rows):\n",
    "        samples_shape = [num_rows, self.length // self.sampling_rate]\n",
    "        samples_shape.extend(self.data1.shape[1:])\n",
    "        targets_shape = [num_rows]\n",
    "        targets_shape.extend(self.targets.shape[1:])\n",
    "        return np.empty(samples_shape), np.empty(samples_shape), np.empty(targets_shape)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.shuffle:\n",
    "            rows = np.random.randint(\n",
    "                self.start_index, self.end_index + 1, size=self.batch_size)\n",
    "        else:\n",
    "            i = self.start_index + self.batch_size * self.stride * index\n",
    "            rows = np.arange(i, min(i + self.batch_size *\n",
    "                                    self.stride, self.end_index + 1), self.stride)\n",
    "\n",
    "        samples1, samples2, targets = self._empty_batch(len(rows))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - self.length, rows[j], self.sampling_rate)\n",
    "            samples1[j] = self.data1[indices]\n",
    "            samples2[j] = self.data2[indices]\n",
    "            targets[j] = self.targets[rows[j]]\n",
    "        if self.reverse:\n",
    "            return [samples1[:, ::-1, ...], samples2[:, ::-1, ...]], targets\n",
    "        return [samples1, samples2], targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.arange(0,100).reshape(-1,1)\n",
    "data2 = np.arange(0,100).reshape(-1,1)\n",
    "data_gen = TimeseriesGeneratorTwoInputs(data1, data2, data2, length=WINDOW_LENGTH, sampling_rate=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 4, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 4, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 100)          40800       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  (None, 100)          40800       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 200)          0           lstm_9[0][0]                     \n",
      "                                                                 lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 20)           4020        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            21          dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 85,641\n",
      "Trainable params: 85,641\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_dim = 1\n",
    "\n",
    "# First layer\n",
    "input1 = Input(shape=(WINDOW_LENGTH, data_dim))\n",
    "input2 = Input(shape=(WINDOW_LENGTH, data_dim))\n",
    "lstm1 = LSTM(100)(input1)\n",
    "lstm2 = LSTM(100)(input2)\n",
    "\n",
    "# Second layer\n",
    "merged = keras.layers.concatenate([lstm1, lstm2])\n",
    "\n",
    "# Third layer\n",
    "hidden = Dense(20, activation='relu')(merged)\n",
    "output = Dense(data_dim, activation='linear')(hidden)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 63ms/step - loss: 2304.6477 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1496.8769 - acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 773.9431 - acc: 0.0312\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 312.1340 - acc: 0.0938\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 136.2790 - acc: 0.0625\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 55.5633 - acc: 0.2188\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 25.0596 - acc: 0.0938\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 11.9308 - acc: 0.0938\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 9.8678 - acc: 0.1562  ETA: 0s - loss: 10.1129 - acc: 0.000\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.8735 - acc: 0.1875\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 6.9226 - acc: 0.2812\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 7.1577 - acc: 0.1562\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 5.5719 - acc: 0.2500\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 5.2186 - acc: 0.2500\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 5.4549 - acc: 0.1875\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.8789 - acc: 0.2812\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 7.3475 - acc: 0.4062\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 2.6431 - acc: 0.3438\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 5.3586 - acc: 0.2812\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 4.3871 - acc: 0.2812\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 4.0671 - acc: 0.1875\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 4.2554 - acc: 0.3438\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 5.0778 - acc: 0.2500\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.5511 - acc: 0.1875\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.0089 - acc: 0.1875\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3.9304 - acc: 0.1875\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 4.1473 - acc: 0.4062\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.2874 - acc: 0.4062\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.4132 - acc: 0.3750\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.8469 - acc: 0.2188\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 3.0509 - acc: 0.2500\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 3.0717 - acc: 0.3438\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.5178 - acc: 0.3438\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.2087 - acc: 0.3750\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 3.1665 - acc: 0.2188\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.8151 - acc: 0.2812\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.6251 - acc: 0.3438\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.4916 - acc: 0.3438\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.4056 - acc: 0.2500\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.7844 - acc: 0.1875\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6792 - acc: 0.3125\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.8809 - acc: 0.2188\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.4726 - acc: 0.3750\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 3.4753 - acc: 0.2812\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.1072 - acc: 0.4062\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 2.4430 - acc: 0.4375\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.9202 - acc: 0.3750\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.3381 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3882 - acc: 0.6250\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 2.6864 - acc: 0.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f776dffbfd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now train the model\n",
    "# batch_size should be appropriate to your memory size\n",
    "# number of epochs should be higher for real world problems\n",
    "# model.fit(X_train, y_train, batch_size=450, epochs=10, validation_split=0.05)\n",
    "model.fit_generator(generator=data_gen,\n",
    "                    steps_per_epoch=32,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83.56241]]\n"
     ]
    }
   ],
   "source": [
    "input1 = np.arange(80,84).reshape(1,4,1)\n",
    "input2 = np.arange(80,84).reshape(1,4,1) #np.arange(80,85).reshape(1,5,1)\n",
    "\n",
    "predicted = model.predict([input1,input2])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Stateful predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Inspired by this [question](https://stackoverflow.com/questions/38081263/stream-output-of-predictions-in-keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use keras TimeseriesGenerator to turn a sequence\n",
    "# into multiple windows of sequences\n",
    "WINDOW_LENGTH = 4\n",
    "\n",
    "def get_generator(data, targets, window_length = 5, batch_size = 32):\n",
    "    while True:\n",
    "        data_gen = TimeseriesGenerator(data, targets, length=window_length, \n",
    "                                       sampling_rate=1, batch_size=batch_size)\n",
    "        for i in range(len(data_gen)):\n",
    "            x, y = data_gen[i]\n",
    "            yield x, y\n",
    "\n",
    "data = np.arange(0,100).reshape(-1,1)\n",
    "data_gen_custom = get_generator(data, data, window_length=WINDOW_LENGTH, batch_size=1)\n",
    "data_gen = TimeseriesGenerator(data, data, length=WINDOW_LENGTH, sampling_rate=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 4, 1)              0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 42,841\n",
      "Trainable params: 42,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_dim = 1\n",
    "input1 = Input(shape=(WINDOW_LENGTH, data_dim))\n",
    "lstm1 = LSTM(100)(input1)\n",
    "\n",
    "hidden = Dense(20, activation='relu')(lstm1)\n",
    "output = Dense(data_dim, activation='linear')(hidden)\n",
    "\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 1207.1231 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3078.6028 - acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1717.6385 - acc: 0.4375\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 232.1851 - acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1245.5542 - acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 721.2272 - acc: 0.2812\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9430 - acc: 0.3125\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 230.0934 - acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 174.0416 - acc: 0.0312\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5908 - acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.7939 - acc: 0.0938\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 12.8146 - acc: 0.0625\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9901 - acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.0728 - acc: 0.0625\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.6761 - acc: 0.0938\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.9565 - acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.9506 - acc: 0.0312\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8982 - acc: 0.1562\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.5198 - acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0914 - acc: 0.0625\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7808 - acc: 0.1562\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.3043 - acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.0724 - acc: 0.0312\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6515 - acc: 0.2188\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1058 - acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8847 - acc: 0.0625\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6154 - acc: 0.2500\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9961 - acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.6972 - acc: 0.0312\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5769 - acc: 0.2812\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8984 - acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.6221 - acc: 0.0312\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5652 - acc: 0.2500\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8362 - acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.5412 - acc: 0.0312\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5493 - acc: 0.3125\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7846 - acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.4983 - acc: 0.0312\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5343 - acc: 0.3125\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.7628 - acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4318 - acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5104 - acc: 0.3438\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7356 - acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3171 - acc: 0.0312\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5258 - acc: 0.3125\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7194 - acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.2677 - acc: 0.0625\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5309 - acc: 0.2812\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7090 - acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.1772 - acc: 0.0938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4b7908c2d0>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now train the model\n",
    "# batch_size should be appropriate to your memory size\n",
    "model.fit_generator(generator=data_gen_custom,\n",
    "                    steps_per_epoch=32,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88.76638]]\n"
     ]
    }
   ],
   "source": [
    "input1 = np.arange(80,84).reshape(1,WINDOW_LENGTH,1)\n",
    "\n",
    "predicted = model.predict(input1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Handling large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Required datasets and expected size:\n",
    "\n",
    "#### 1. Units\n",
    "- **Num units**: ~2,000,000 (approx 100 units per song)\n",
    "- **Size per unit**: 36864 bytes (`unit.nbytes` = 8448 elements * float16)\n",
    "- **Total size**: ~74GB (2,000,000 * 37kB) \n",
    "\n",
    "Expect less because many songs don't have pianorolls, and many pianorolls have empty units.\n",
    "\n",
    "~~_Consider changing to float16?_~~ Done.\n",
    "\n",
    "#### 2. Sequence\n",
    "- **Window size**: 4\n",
    "- **Input-Comp-y**: 9 units (4 + 4 + 1)\n",
    "- **Num datapoints**: ~2,000,000\n",
    "- **Total size**: ~700GB = 9 x 2,000,000 x 37kB\n",
    "\n",
    "Let's not do it like this. :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Using numpy memory maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpIRs4Qf/newfile.dat'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "filename = path.join(mkdtemp(), 'newfile.dat') # create temp file for memmap\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = np.memmap(filename, dtype='float32', mode='w+', shape=(200000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Using hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Basics\n",
    "From the [docs](http://docs.h5py.org/en/latest/quick.html#quick)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "filename = \"mytestfile.hdf5\"\n",
    "with h5py.File(filename, \"w\") as f:\n",
    "    dset = f.create_dataset(\"mydataset\", (100,), dtype='float32')\n",
    "    print(dset.shape)\n",
    "    dset = np.arange(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'mydataset']\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('mytestfile.hdf5', 'r') as f:\n",
    "    print(f.keys())\n",
    "    print(f['mydataset'][...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Resizable datasets\n",
    "From [this StackOverflow question](https://stackoverflow.com/questions/25655588/incremental-writes-to-hdf5-with-h5py?rq=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NUM_PITCHES = 2\n",
    "NUM_TICKS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2, 2)\n",
      "(6, 2, 2)\n",
      "(14, 2, 2)\n",
      "(20, 2, 2)\n",
      "[[[0.8500343  0.38689092]\n",
      "  [0.77727604 0.81265455]]\n",
      "\n",
      " [[0.02969339 0.9345693 ]\n",
      "  [0.7920879  0.6325009 ]]\n",
      "\n",
      " [[0.469871   0.9079007 ]\n",
      "  [0.5759628  0.30690378]]\n",
      "\n",
      " [[0.8580788  0.4767191 ]\n",
      "  [0.5276081  0.67525065]]\n",
      "\n",
      " [[0.5185089  0.28715146]\n",
      "  [0.693969   0.04807708]]\n",
      "\n",
      " [[0.92874354 0.58465916]\n",
      "  [0.55231214 0.9883768 ]]\n",
      "\n",
      " [[0.558073   0.5707375 ]\n",
      "  [0.35652852 0.9255937 ]]\n",
      "\n",
      " [[0.15850353 0.6380559 ]\n",
      "  [0.03733948 0.8015228 ]]\n",
      "\n",
      " [[0.4627496  0.29987308]\n",
      "  [0.58572066 0.4374565 ]]\n",
      "\n",
      " [[0.2547735  0.0240215 ]\n",
      "  [0.32339704 0.9560488 ]]\n",
      "\n",
      " [[0.5013472  0.15711232]\n",
      "  [0.19503206 0.35899225]]\n",
      "\n",
      " [[0.20521723 0.16368036]\n",
      "  [0.39066824 0.33925653]]\n",
      "\n",
      " [[0.00412564 0.1533687 ]\n",
      "  [0.40302402 0.13068216]]\n",
      "\n",
      " [[0.1632349  0.3924986 ]\n",
      "  [0.28279847 0.44609523]]\n",
      "\n",
      " [[0.07656287 0.96613854]\n",
      "  [0.48486853 0.5650878 ]]\n",
      "\n",
      " [[0.6720959  0.5388782 ]\n",
      "  [0.01575743 0.23220679]]\n",
      "\n",
      " [[0.28818586 0.02435029]\n",
      "  [0.15015216 0.9223505 ]]\n",
      "\n",
      " [[0.27819735 0.8705458 ]\n",
      "  [0.01930406 0.8838827 ]]\n",
      "\n",
      " [[0.5650662  0.73405254]\n",
      "  [0.7591451  0.19757618]]\n",
      "\n",
      " [[0.00543595 0.6452691 ]\n",
      "  [0.60433894 0.61726624]]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "path = '/tmp/out.h5'\n",
    "os.remove(path)\n",
    "with h5py.File(path, \"a\") as f:\n",
    "    dset = f.create_dataset('units', (0, NUM_PITCHES, NUM_TICKS), maxshape=(None, NUM_PITCHES, NUM_TICKS),\n",
    "                            dtype='float32', chunks=True)\n",
    "    print(dset.shape)\n",
    "\n",
    "    for i in range(3):\n",
    "        # Load pianoroll\n",
    "        # Extract units\n",
    "        M = np.random.randint(5,10)\n",
    "        units = np.random.rand(M, NUM_PITCHES, NUM_TICKS)\n",
    "        \n",
    "        # Append to dataset\n",
    "        dset.resize(dset.shape[0]+M, axis=0)\n",
    "        dset[-M:] = units\n",
    "        \n",
    "        print(dset.shape)\n",
    "\n",
    "    print(dset[:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
