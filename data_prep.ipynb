{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This notebook details the data preparation steps for Comper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grab the dataset\n",
    "1. Go to [https://salu133445.github.io/musegan/dataset](https://salu133445.github.io/musegan/dataset)\n",
    "2. Download the `lpd-5-cleansed.tgz` dataset.\n",
    "3. Extract it into a folder `lpd-5-cleansed`.\n",
    "4. You should see three layers of subfolders labelled 'A'-'J', and then leaf folders named something like `TRJJFLV128F92FC46E/`, each containing a file which looks something like `c28d6d22cf7298890c5cc5f21ac2244d.npz` (this is a numpy zip file, more information [here](https://salu133445.github.io/pypianoroll/save_load.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Flatten all files into one folder\n",
    "\n",
    "1. `cd` to the root of your dataset.\n",
    "2. Check that there are 24474 .npz files using \n",
    "```bash\n",
    "find . -mindepth 2 -type f | wc -l\n",
    "```\n",
    "3. Move all files to the current directory for easier access later: \n",
    "```bash\n",
    "find . -mindepth 2 -type f -print -exec mv --backup=numbered {} . \\;\n",
    "``` \n",
    "([What?](https://askubuntu.com/questions/146634/shell-script-to-move-all-files-from-subfolders-to-parent-folder))\n",
    "4. Rename all \"~#~\" extensions to \"~#.npz\" so that numpy doesn't reject the file later on.\n",
    "```bash\n",
    "rename 's/\\~$/\\.npz/' *~\n",
    "```\n",
    "4. Remove the empty folders `rm -r */` (Don't forget the slash!)\n",
    "5. Confirm that you have the correct number of files using `ls | wc -l`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Grab a random subset of files to play with\n",
    "We'll use 100 files to start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pypianoroll\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "LPD5_DIR = \"/media/junshern/s_drive/FYP/MIDI/lpd_5_cleansed_copy\"\n",
    "DATA_DIR = \"./pianorolls\"\n",
    "NUM_FILES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists.\n",
      "['825743bc60816514d61574b44abc4d22.npz', '035d2131e824eb51878007013786806a.npz', 'c7523bfd41d67de23b7e1d7575284821.npz', 'bc11aedb9c44074c732f6aac7ac9a3a3.npz.~4.npz', 'ee98ebdda35b94d0d6ba19c194db9911.npz', 'e9bfc85ab76f224f686b8a142570ab6e.npz', 'd1002f0b1b1e687baa750467113e219c.npz', '1fc99c6776860dbec8fe64dd4cc52e73.npz', '9e1d04631b8ad65addff1a9f755132aa.npz.~1.npz', 'c016f976fb71e75d8fcd931e08f64ae6.npz.~1.npz']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a new directory for our pianorolls\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)\n",
    "    # Grab a random subset of files from our LPD5 dataset to play with\n",
    "    files_subset = random.sample(os.listdir(LPD5_DIR), NUM_FILES) # Sampling without replacement\n",
    "    for filename in files_subset:\n",
    "        src = os.path.join(LPD5_DIR, filename)\n",
    "        dest = os.path.join(DATA_DIR, filename)\n",
    "        shutil.copyfile(src, dest)\n",
    "    print \"Copied\", NUM_FILES, \"files to\", DATA_DIR, \".\"\n",
    "else:\n",
    "    print \"Directory already exists.\"\n",
    "\n",
    "# Print the first 10 files of our chosen subset\n",
    "print(os.listdir(DATA_DIR)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect the data\n",
    "\n",
    "From the MuseGAN page:\n",
    "\n",
    "> In LPD-5, the tracks of each multi-track piano-rolls are merged into five common categories: bass, drums, piano, guitar and strings according to the program numbers provided in the MIDI files. Note that instruments out of the list are considered as part of the strings\n",
    "\n",
    "We use [pypianoroll](https://github.com/salu133445/pypianoroll), created by the authors of MuseGAN to manipulate the data. The pypianoroll library gives us a ton of helpful methods which makes it easy to find out more about each file. (pypianoroll [docs](https://salu133445.github.io/pypianoroll/index.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb352a13a60d723832075d66b5048642.npz.~1.npz\n",
      "Tempo:  [90.00009 90.00009 90.00009 ... 90.00009 90.00009 90.00009]\n",
      "Beat resolution:  24\n",
      "\n",
      "#####################\n",
      "Name:  Guitar\n",
      "isDrum:  False\n",
      "Program:  24\n",
      "Active length:  9698\n",
      "Active pitch range:  (49, 78)\n",
      "\n",
      "\n",
      "#####################\n",
      "Name:  Piano\n",
      "isDrum:  False\n",
      "Program:  0\n",
      "Empty pianoroll.\n",
      "\n",
      "\n",
      "#####################\n",
      "Name:  Bass\n",
      "isDrum:  False\n",
      "Program:  32\n",
      "Active length:  10848\n",
      "Active pitch range:  (34, 44)\n",
      "\n",
      "\n",
      "#####################\n",
      "Name:  Drums\n",
      "isDrum:  True\n",
      "Program:  0\n",
      "Active length:  10842\n",
      "Active pitch range:  (35, 70)\n",
      "\n",
      "\n",
      "#####################\n",
      "Name:  Strings\n",
      "isDrum:  False\n",
      "Program:  48\n",
      "Active length:  10812\n",
      "Active pitch range:  (58, 77)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def printInfo(track):\n",
    "    print \"\\n#####################\"\n",
    "    print \"Name: \", track.name\n",
    "    print \"isDrum: \", track.is_drum\n",
    "    print \"Program: \", track.program\n",
    "    if len(track.pianoroll):\n",
    "        print \"Active length: \", track.get_active_length()\n",
    "        print \"Active pitch range: \", track.get_active_pitch_range()\n",
    "    else:\n",
    "        print \"Empty pianoroll.\"\n",
    "    print \"\"\n",
    "\n",
    "# Pick a file to look at\n",
    "filename = random.choice(os.listdir(DATA_DIR))\n",
    "print(filename)\n",
    "# Load pianoroll file as a multitrack object\n",
    "multi = pypianoroll.Multitrack(os.path.join(DATA_DIR, filename))\n",
    "print \"Tempo: \", multi.tempo\n",
    "print \"Beat resolution: \", multi.beat_resolution\n",
    "# Show some info about the pianoroll\n",
    "for track in multi.tracks:\n",
    "    printInfo(track)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract pianorolls from the Piano track of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete. Number of pianorolls collected:  70\n"
     ]
    }
   ],
   "source": [
    "pianorolls = [] # List to hold all our piano rolls\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    # Load pianoroll file as a multitrack object\n",
    "    multi = pypianoroll.Multitrack(os.path.join(DATA_DIR, filename))\n",
    "    for track in multi.tracks:\n",
    "        # Non-empty piano pianoroll\n",
    "        if track.name == \"Piano\" and track.pianoroll.shape[0] > 0:\n",
    "            pianorolls.append(track.pianoroll)\n",
    "print \"Complete. Number of pianorolls collected: \", len(pianorolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Create dataset for training/testing\n",
    "\n",
    "Our model deals with predicting musical _units_ of a pianoroll, which can be for example 4 beats of a pianoroll depending on the chosen `BEATS_PER_UNIT`. The datasets we prepare must then correspond to input/output pairs of musical units.\n",
    "\n",
    "### Model objectives\n",
    "\n",
    "Given an input unit at time $t$, predict an output unit which may be either (depending on a user-selected prediction mode)\n",
    "1. The following unit at time $t+1$\n",
    "2. An accompaniment unit at time $t$\n",
    "3. An accompaniment unit at time $t+1$\n",
    "\n",
    "In the 1st case, the output is simply the _next-step prediction_, used commonly by most composition algorithms. \n",
    "\n",
    "In the 2nd case, the output is an _accompanying pianoroll of the current unit_, either the left-accompaniment or right-accompaniment. For example, given an input pianoroll which is a right-accompaniment, the model will be expected to predict the left-accompaniment for that input.\n",
    "\n",
    "In the 3rd (expectedly most difficult) case, the output is an _accompanying pianoroll of the next unit_, either the left-accompaniment or right-accompaniment. For example, given an input pianoroll which is a right-accompaniment, the model will be expected to predict the left-accompaniment at the next time step.\n",
    "\n",
    "### Unit creation\n",
    "\n",
    "To help the model learn accompaniments, we split each pianoroll from our dataset into two complementary pianorolls which serve as accompaniments for each other. This is done in a naive way, using the `PARTITION_NOTE` as the splitting point to divide the pianoroll along the pitch axis into left- and right- accompaniments (as in left and right hand of a piano player). This approach was inspired by \\[Bretan et al\\]. \n",
    "\n",
    "Each of these pianoroll segments (of fixed tick-length and only containing notes for either left- or right- accompaniments) will be used as a single unit, and is represented by a matrix of shape `[TICKS_PER_UNIT, NUM_PITCHES=128]`. \n",
    "\n",
    "The input and output matrices of our model will have the same shape.\n",
    "\n",
    "### Data structure\n",
    "\n",
    "Since all units have the same shape, this makes it easy to store the data as a 3-dimensional matrix of depth $M$, where $M$ is the number of units (data points).\n",
    "\n",
    "We will create 4 matrices comprising of: the input units, the next step units, the accompaniment units, and the next step accompaniment units. \n",
    "\n",
    "```\n",
    "input_units.shape = [M, TICKS_PER_UNIT, NUM_PITCHES=128]\n",
    "input_units_next.shape = [M, TICKS_PER_UNIT, NUM_PITCHES=128]\n",
    "comp_units.shape = [M, TICKS_PER_UNIT, NUM_PITCHES=128]\n",
    "comp_units_next.shape = [M, TICKS_PER_UNIT, NUM_PITCHES=128]\n",
    "```\n",
    "\n",
    "The unit dimension is ordered are ordered such that the $i$-th input has an output at the $i$-th element of each output matrix. (eg. given `input_units[i,:,:]`, the model should predict `input_units_next[i,:,:]`, `comp_units[i,:,:]`, or `comp_units_next[i,:,:]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset definitions\n",
    "NUM_PITCHES = 128\n",
    "PARTITION_NOTE = 60 # Break into left- and right-accompaniments at middle C\n",
    "BEAT_RESOLUTION = 24 # This is set by the encoding of the lpd-5 dataset, corresponds to number of ticks per beat\n",
    "BEATS_PER_UNIT = 4\n",
    "TICKS_PER_UNIT = BEATS_PER_UNIT * BEAT_RESOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_units(pianoroll):\n",
    "    \"\"\"\n",
    "    Given an input pianoroll, return [input_units, input_units_next, comp_units, comp_units_next_shape]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare outputs (M is not known yet, so leave as M=1)\n",
    "    input_units = np.zeros([1, TICKS_PER_UNIT, NUM_PITCHES])\n",
    "    input_units_next = np.zeros([1, TICKS_PER_UNIT, NUM_PITCHES])\n",
    "    comp_units = np.zeros([1, TICKS_PER_UNIT, NUM_PITCHES])\n",
    "    comp_units_next = np.zeros([1, TICKS_PER_UNIT, NUM_PITCHES])\n",
    "    \n",
    "    # Split pianoroll into left- and right- accompaniments\n",
    "    left_comp = pianoroll\n",
    "    left_comp[:, PARTITION_NOTE:] = 0\n",
    "    right_comp = pianoroll\n",
    "    right_comp[:, :PARTITION_NOTE] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    assert(input_units.shape[1] == 128)\n",
    "    \n",
    "    return [input_units, input_units_next, comp_units, comp_units_next]\n",
    "\n",
    "proll = random.choice(pianorolls)\n",
    "[input_units, input_units_next, comp_units, comp_units_next] = create_units(proll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
